## hash table

> 思考题：Word 文档中单词拼写检查功能是如何实现的？

- **散列表用的是数组支持按照下标随机访问数据(时间复杂度是 O(1) 的特性)的特性，所以散列表其实就是数组的一种扩展，由数组演化而来。可以说，如果没有数组，就没有散列表。**
- 散列思想。其中，参赛选手的编号我们叫作**键**（key）或者**关键字**。我们用它来标识一个选手。我们把参赛编号转化为数组下标的映射方法就叫作**散列函数**（或“Hash 函数”“哈希函数”），而散列函数计算得到的值就叫作**散列值**（或“Hash 值”“哈希值”）。![](images/92c89a57e21f49d2f14f4424343a2773.jpg)
- **三点**散列函数**设计的****基本要求**：

    1.  散列函数计算得到的散列值是一个非负整数；
    
    2.  如果 key1 = key2，那 hash(key1) == hash(key2)；
    
    3.  如果 key1 ≠ key2，那 hash(key1) ≠ hash(key2)。
- 散列冲突
  - 开放寻址法（open addressing）
      - 线性探测![](images/fe7482ba09670cbe05a9dfe4dd49bd1d.jpg) 
      - 二次探测
      
          > 所谓二次探测，跟线性探测很像，线性探测每次探测的步长是 1，那它探测的下标序列就是 hash(key)+0，hash(key)+1，hash(key)+2……而二次探测探测的步长就变成了原来的“二次方”，也就是说，它探测的下标序列就是 hash(key)+0，hash(key)+12，hash(key)+22……
      - 双重散列
        
          > 所谓双重散列，意思就是不仅要使用一个散列函数。我们使用一组散列函数 hash1(key)，hash2(key)，hash3(key)……我们先用第一个散列函数，如果计算得到的存储位置已经被占用，再用第二个散列函数，依次类推，直到找到空闲的存储位置。

      - 装载因子
       
          > 当散列表中空闲位置不多的时候，散列冲突的概率就会大大提高。为了尽可能保证散列表的操作效率，一般情况下，我们会尽可能保证散列表中有一定比例的空闲槽位。我们用装载因子（load factor）来表示空位的多少。
  
  
  - 链表法（chaining）![](images/a4b77d593e4cb76acb2b0689294ec17f.jpg)
  
- 课后思考

    >  1. 假设我们有 10 万条 URL 访问日志，如何按照访问次数给 URL 排序？
    
    遍历 10 万条数据，以 URL 为 key，访问次数为 value，存入散列表，同时记录下访问次数的最大值 K，时间复杂度 O(N)。
    
    如果 K 不是很大，可以使用[桶排序](/data-structure/sort##bucket-sort)，时间复杂度 O(N)。如果 K 非常大（比如大于 10 万），就使用快速排序，复杂度 O(NlogN)。
    
    >  2. 有两个字符串数组，每个数组大约有 10 万条字符串，如何快速找出两个数组中相同的字符串？
    
    以第一个字符串数组构建散列表，key 为字符串，value 为出现次数。再遍历第二个字符串数组，以字符串为 key 在散列表中查找，如果 value 大于零，说明存在相同字符串。时间复杂度 O(N)。
    
    
> 散列表碰撞攻击了解一下

通过精心构造的数据，使得所有的数据经过散列函数之后，都散列到同一个槽里。如果我们使用的是基于链表的冲突解决方法，查询的时间复杂度就从 O(1) 急剧退化为 O(n)。如果散列表中有 10 万个数据，退化后的散列表查询的效率就下降了 10 万倍。这样就有可能因为查询操作消耗大量 CPU 或者线程资源，导致系统无法响应其他请求，从而达到拒绝服务攻击（DoS）的目的。


**如何实现这样一个工业级散列表呢？**
 *   设计一个合适的散列函数；

*   定义装载因子阈值，并且设计动态扩容策略；

*   选择合适的散列冲突解决方法。


**散列表和链表经常一块使用:**

散列表是动态数据结构,散列表中的数据都是通过散列函数打乱之后无规律存储的。它无法支持按照某种顺序快速地遍历数据。如果希望按照顺序遍历散列表中的数据，那我们需要将散列表中的数据拷贝到数组中，然后排序，再遍历。为了解决这个问题，我们将散列表和链表（或者跳表）结合在一起使用。

比如：用链表实现LRU缓存淘汰算法，查找的时间复杂度很高为O(n)。使用散列表和链表实现LRU缓存淘汰算法，查找的时间复杂度会降低到O(1)。











